name: spectro


model:
  arch:
    _target_: models.transformer_decoder.SpectroTFDecoder
    vocab_size: 51
    num_layers: 6
    d_model: 512
    d_ff: 2048
    num_heads: 8
    d_embeddings: 768
    m: 16
    max_len: 77
    use_positional_embeddings: true

    # _target_: models.transformer.TransformerDecoder
    # d_model: 512
    # nhead: 4
    # dim_feedforward: 512
    # num_layers: 6
    # dropout: 0.1
    # activation: 'relu'
    # norm_first: True
    # batch_first: True
    # vocab_size: 51
    # max_len: 77
    # start_token_id: 2
    # eos_token_id: 3
    # pad_token_id: 0
  jirvis:
    _target_: models.resnet50.ResNetFeatureExtractor
    num_labels: 25
    model_name: R50 # R101, R52
    model_type: 3_layer   #       standard, residual, squeeze, 4_layer
    channels: 3
  nmr_enc:
    _target_: models.transformer_encoder.NMRTransformerRegressor
    vocab_size: 
    d_model: 256
    nhead: 8
    dim_feedforward: 1024
    num_layers: 4
    num_classes: 15 #if hall_kier, num classes: 15. if 'numerical' or 'binary', num classes: 19
    max_len: 300
    dropout: 0.1
    activation: 'relu'
    norm_first: True
    batch_first: True
    use_scalar: True
    n_scalar_features: 1  
    scalar_num_layers: 2
    scalar_hidden_dim: ${system.model.nmr_enc.d_model}
  tokenizer:
    _target_: models.nmr_tokenizer.NMRTokenizer
    max_length: 300
    vocab_path: /home/rudra/rudra_learns/bruh/nmr_vocab_2.json
    split_decimals: False



train:
  optimizer:
    _target_: torch.optim.AdamW
    lr: 3e-4
    weight_decay: 0.01

  loss_func:
    _target_: torch.nn.CrossEntropyLoss
    ignore_index: 0
    # pos_weight:            # ${class_weights}

  lr_scheduler:


  trainer:
    _target_: pytorch_lightning.Trainer
    _convert_: all
    max_epochs: 40 # 100 # 60000
    check_val_every_n_epoch: 1
    # val_check_interval : 1 # 500 # 50 # 3000
    log_every_n_steps: 1
    precision: 16-mixed
    # limit_val_batches: 1
    # limit_test_batches: 1
    # devices:
    #   - ${device.id}

    # Multi gpu training flags:
    accelerator: gpu
    devices: [1]

    strategy: auto
    #strategy: ddp_find_unused_parameters_true

    enable_model_summary: false

    callbacks:
    - _target_: pytorch_lightning.callbacks.ModelCheckpoint
      monitor: 'val_loss'
      mode: 'min'
      save_top_k: 1
      save_last: true
      filename: 'spectro-{epoch}-{best_acc:.4f}'
      
#     - _target_: pytorch_lightning.callbacks.ModelCheckpoint
# #       dirpath: ${output_dir}/${system.name}/checkpoints
#       filename: "{epoch}-{r2:.4f}"
#       monitor: 'val_r2'
#       mode: 'max'
#       save_top_k: 1
#       save_last: false
#       verbose: true
      
    - _target_: pytorch_lightning.callbacks.TQDMProgressBar
      leave: true
      refresh_rate: 1

    logger:
      _target_: pytorch_lightning.loggers.TensorBoardLogger
      save_dir: ${output_dir}/${system.name}
      name: '.'
      version: '.'
